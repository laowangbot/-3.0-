#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›‘å¬ç³»ç»Ÿä¼˜åŒ–éªŒè¯è„šæœ¬
æµ‹è¯•ä¼˜åŒ–åçš„ç³»ç»Ÿæ€§èƒ½
"""

import asyncio
import logging
import sys
import os
from datetime import datetime, timedelta
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import get_config
from monitoring_engine import MonitoringEngine
from pyrogram import Client

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class OptimizationTester:
    """ä¼˜åŒ–æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.config = get_config()
        self.client = None
        self.monitoring_engine = None
        
    async def setup(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        print("ğŸ”§ è®¾ç½®æµ‹è¯•ç¯å¢ƒ")
        print("=" * 50)
        
        # è·å–é…ç½®
        api_id = self.config.get('api_id')
        api_hash = self.config.get('api_hash')
        
        if not api_id or not api_hash:
            print("âŒ ç¼ºå°‘APIé…ç½®")
            return False
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        self.client = Client("optimization_test", api_id=api_id, api_hash=api_hash)
        
        # åˆ›å»ºç›‘å¬å¼•æ“
        self.monitoring_engine = MonitoringEngine(self.client, self.config)
        
        print("âœ… æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")
        return True
    
    def test_configuration(self):
        """æµ‹è¯•é…ç½®ä¼˜åŒ–"""
        print("\nğŸ§ª æµ‹è¯•é…ç½®ä¼˜åŒ–")
        print("=" * 50)
        
        # æ£€æŸ¥å…³é”®é…ç½®
        config_tests = [
            ("max_concurrent_tasks", 50, "å¹¶å‘ä»»åŠ¡æ•°"),
            ("max_user_concurrent_tasks", 100, "ç”¨æˆ·å¹¶å‘ä»»åŠ¡æ•°"),
            ("batch_size", 10, "æ‰¹å¤„ç†å¤§å°"),
            ("check_interval", 3, "æ£€æŸ¥é—´éš”"),
            ("max_messages_per_check", 200, "æœ€å¤§æ¶ˆæ¯æ£€æŸ¥æ•°"),
            ("api_rate_limit", 30, "APIé™åˆ¶"),
            ("message_delay", 0.02, "æ¶ˆæ¯å»¶è¿Ÿ"),
            ("media_group_delay", 0.5, "åª’ä½“ç»„å»¶è¿Ÿ")
        ]
        
        all_passed = True
        for key, expected, description in config_tests:
            actual = self.config.get(key)
            if actual == expected:
                print(f"âœ… {description}: {actual} (ç¬¦åˆé¢„æœŸ)")
            else:
                print(f"âŒ {description}: {actual} (é¢„æœŸ: {expected})")
                all_passed = False
        
        return all_passed
    
    def test_performance_calculation(self):
        """æµ‹è¯•æ€§èƒ½è®¡ç®—"""
        print("\nğŸ“Š æµ‹è¯•æ€§èƒ½è®¡ç®—")
        print("=" * 50)
        
        # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®
        test_data = [
            {"total": 1000, "successful": 950, "failed": 50},
            {"total": 500, "successful": 400, "failed": 100},
            {"total": 2000, "successful": 1900, "failed": 100},
            {"total": 0, "successful": 0, "failed": 0}
        ]
        
        for i, data in enumerate(test_data, 1):
            total = data["total"]
            successful = data["successful"]
            failed = data["failed"]
            
            success_rate = (successful / total * 100) if total > 0 else 0
            failure_rate = (failed / total * 100) if total > 0 else 0
            
            print(f"æµ‹è¯• {i}: æ€»æ¶ˆæ¯ {total}, æˆåŠŸ {successful}, å¤±è´¥ {failed}")
            print(f"  æˆåŠŸç‡: {success_rate:.2f}%, å¤±è´¥ç‡: {failure_rate:.2f}%")
            
            # æ£€æŸ¥æ€§èƒ½å‘Šè­¦
            if success_rate < self.config.get('performance_alert_threshold', 0.9) * 100:
                print(f"  âš ï¸ æ€§èƒ½å‘Šè­¦: æˆåŠŸç‡ {success_rate:.2f}% ä½äºé˜ˆå€¼")
            else:
                print(f"  âœ… æ€§èƒ½æ­£å¸¸")
        
        return True
    
    def test_api_rate_limiting(self):
        """æµ‹è¯•APIé™åˆ¶é€»è¾‘"""
        print("\nğŸš¦ æµ‹è¯•APIé™åˆ¶é€»è¾‘")
        print("=" * 50)
        
        # æ¨¡æ‹ŸAPIè°ƒç”¨æ—¶é—´è®°å½•
        api_call_times = []
        current_time = datetime.now()
        
        # æ¨¡æ‹Ÿ1åˆ†é’Ÿå†…çš„APIè°ƒç”¨
        for i in range(35):  # è¶…è¿‡é™åˆ¶çš„è°ƒç”¨æ¬¡æ•°
            call_time = current_time - timedelta(seconds=i*2)  # æ¯2ç§’ä¸€æ¬¡è°ƒç”¨
            api_call_times.append(call_time)
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        recent_calls = [
            call_time for call_time in api_call_times
            if current_time - call_time < timedelta(minutes=1)
        ]
        
        rate_limit = self.config.get('api_rate_limit', 30)
        print(f"APIè°ƒç”¨æ¬¡æ•°: {len(recent_calls)}")
        print(f"APIé™åˆ¶: {rate_limit}")
        
        if len(recent_calls) >= rate_limit:
            print("âš ï¸ è¶…è¿‡APIé™åˆ¶ï¼Œéœ€è¦ç­‰å¾…")
            oldest_call = min(recent_calls)
            wait_time = 60 - (current_time - oldest_call).total_seconds()
            print(f"éœ€è¦ç­‰å¾…: {wait_time:.2f} ç§’")
        else:
            print("âœ… APIè°ƒç”¨åœ¨é™åˆ¶èŒƒå›´å†…")
        
        return True
    
    def test_batch_processing(self):
        """æµ‹è¯•åˆ†æ‰¹å¤„ç†é€»è¾‘"""
        print("\nğŸ“¦ æµ‹è¯•åˆ†æ‰¹å¤„ç†é€»è¾‘")
        print("=" * 50)
        
        # æ¨¡æ‹Ÿä¸åŒæ•°é‡çš„é¢‘é“
        test_cases = [
            {"channels": 5, "expected_batches": 1},
            {"channels": 15, "expected_batches": 2},
            {"channels": 30, "expected_batches": 3},
            {"channels": 50, "expected_batches": 5},
            {"channels": 100, "expected_batches": 10}
        ]
        
        batch_size = self.config.get('batch_size', 10)
        
        for case in test_cases:
            channels = case["channels"]
            expected_batches = case["expected_batches"]
            
            actual_batches = (channels + batch_size - 1) // batch_size
            
            print(f"é¢‘é“æ•°: {channels}, æ‰¹å¤„ç†å¤§å°: {batch_size}")
            print(f"é¢„æœŸæ‰¹æ¬¡æ•°: {expected_batches}, å®é™…æ‰¹æ¬¡æ•°: {actual_batches}")
            
            if actual_batches == expected_batches:
                print("âœ… åˆ†æ‰¹è®¡ç®—æ­£ç¡®")
            else:
                print("âŒ åˆ†æ‰¹è®¡ç®—é”™è¯¯")
        
        return True
    
    def test_error_recovery(self):
        """æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶"""
        print("\nğŸ”„ æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶")
        print("=" * 50)
        
        # æµ‹è¯•æŒ‡æ•°é€€é¿
        base_delay = self.config.get('api_retry_delay', 2)
        backoff_factor = self.config.get('api_backoff_factor', 2)
        max_errors = self.config.get('max_consecutive_errors', 5)
        
        print(f"åŸºç¡€å»¶è¿Ÿ: {base_delay} ç§’")
        print(f"é€€é¿å› å­: {backoff_factor}")
        print(f"æœ€å¤§è¿ç»­é”™è¯¯: {max_errors}")
        
        for error_count in range(1, 8):
            retry_delay = base_delay * (backoff_factor ** error_count)
            print(f"é”™è¯¯æ¬¡æ•° {error_count}: é‡è¯•å»¶è¿Ÿ {retry_delay} ç§’")
            
            if error_count >= max_errors:
                print(f"  ğŸš¨ è§¦å‘ç†”æ–­å™¨ (è¿ç»­é”™è¯¯ {error_count} æ¬¡)")
        
        return True
    
    def test_memory_management(self):
        """æµ‹è¯•å†…å­˜ç®¡ç†"""
        print("\nğŸ’¾ æµ‹è¯•å†…å­˜ç®¡ç†")
        print("=" * 50)
        
        max_messages = self.config.get('max_processed_messages', 10000)
        cleanup_interval = self.config.get('message_cleanup_interval', 3600)
        memory_threshold = self.config.get('memory_usage_threshold', 0.8)
        
        print(f"æœ€å¤§å­˜å‚¨æ¶ˆæ¯æ•°: {max_messages}")
        print(f"æ¸…ç†é—´éš”: {cleanup_interval} ç§’ ({cleanup_interval/3600:.1f} å°æ—¶)")
        print(f"å†…å­˜ä½¿ç”¨é˜ˆå€¼: {memory_threshold*100:.0f}%")
        
        # è®¡ç®—æ¸…ç†é¢‘ç‡
        messages_per_hour = max_messages / (cleanup_interval / 3600)
        print(f"æ¯å°æ—¶å¤„ç†æ¶ˆæ¯æ•°: {messages_per_hour:.0f}")
        
        return True
    
    async def run_performance_test(self):
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        print("\nğŸš€ è¿è¡Œæ€§èƒ½æµ‹è¯•")
        print("=" * 50)
        
        # æ¨¡æ‹Ÿ30ä¸ªæºé¢‘é“çš„åœºæ™¯
        source_channels = 30
        target_channels = 20
        
        print(f"æ¨¡æ‹Ÿåœºæ™¯: {source_channels} ä¸ªæºé¢‘é“ â†’ {target_channels} ä¸ªç›®æ ‡é¢‘é“")
        
        # è®¡ç®—ç†è®ºæ€§èƒ½
        batch_size = self.config.get('batch_size', 10)
        check_interval = self.config.get('check_interval', 3)
        
        total_batches = (source_channels + batch_size - 1) // batch_size
        full_cycle_time = total_batches * check_interval
        
        print(f"æ‰¹å¤„ç†å¤§å°: {batch_size}")
        print(f"æ£€æŸ¥é—´éš”: {check_interval} ç§’")
        print(f"æ€»æ‰¹æ¬¡æ•°: {total_batches}")
        print(f"å®Œæ•´æ£€æŸ¥å‘¨æœŸ: {full_cycle_time} ç§’")
        
        # è®¡ç®—ååé‡
        max_messages = self.config.get('max_messages_per_check', 200)
        messages_per_cycle = source_channels * max_messages
        messages_per_hour = (messages_per_cycle * 3600) / full_cycle_time
        
        print(f"æ¯å‘¨æœŸæ£€æŸ¥æ¶ˆæ¯æ•°: {messages_per_cycle}")
        print(f"ç†è®ºæ¯å°æ—¶å¤„ç†æ¶ˆæ¯æ•°: {messages_per_hour:.0f}")
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³éœ€æ±‚
        if full_cycle_time <= 10:
            print("âœ… æ£€æŸ¥å‘¨æœŸæ»¡è¶³éœ€æ±‚ (<10ç§’)")
        else:
            print(f"âš ï¸ æ£€æŸ¥å‘¨æœŸè¿‡é•¿: {full_cycle_time} ç§’")
        
        if messages_per_hour >= 10000:
            print("âœ… ååé‡æ»¡è¶³éœ€æ±‚ (>10,000 æ¶ˆæ¯/å°æ—¶)")
        else:
            print(f"âš ï¸ ååé‡å¯èƒ½ä¸è¶³: {messages_per_hour:.0f} æ¶ˆæ¯/å°æ—¶")
        
        return True
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ§ª ç›‘å¬ç³»ç»Ÿä¼˜åŒ–éªŒè¯")
        print("=" * 50)
        
        # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
        if not await self.setup():
            return False
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        tests = [
            ("é…ç½®ä¼˜åŒ–", self.test_configuration),
            ("æ€§èƒ½è®¡ç®—", self.test_performance_calculation),
            ("APIé™åˆ¶", self.test_api_rate_limiting),
            ("åˆ†æ‰¹å¤„ç†", self.test_batch_processing),
            ("é”™è¯¯æ¢å¤", self.test_error_recovery),
            ("å†…å­˜ç®¡ç†", self.test_memory_management),
            ("æ€§èƒ½æµ‹è¯•", self.run_performance_test)
        ]
        
        results = []
        for test_name, test_func in tests:
            try:
                if asyncio.iscoroutinefunction(test_func):
                    result = await test_func()
                else:
                    result = test_func()
                results.append((test_name, result))
            except Exception as e:
                print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥: {e}")
                results.append((test_name, False))
        
        # è¾“å‡ºæµ‹è¯•ç»“æœ
        print("\nğŸ“‹ æµ‹è¯•ç»“æœæ±‡æ€»")
        print("=" * 50)
        
        passed = 0
        total = len(results)
        
        for test_name, result in results:
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{test_name}: {status}")
            if result:
                passed += 1
        
        print(f"\næ€»ä½“ç»“æœ: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡")
        
        if passed == total:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿä¼˜åŒ–æˆåŠŸï¼")
        else:
            print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        return passed == total

def main():
    """ä¸»å‡½æ•°"""
    tester = OptimizationTester()
    
    try:
        result = asyncio.run(tester.run_all_tests())
        return 0 if result else 1
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    exit(main())
