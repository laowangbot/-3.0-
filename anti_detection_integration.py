# ==================== åæŸ¥é‡é›†æˆæ¨¡å— ====================
"""
åæŸ¥é‡é›†æˆæ¨¡å—
å°†æˆäººå†…å®¹åæŸ¥é‡åŠŸèƒ½é›†æˆåˆ°ç°æœ‰çš„æ¬è¿å¼•æ“ä¸­
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from pyrogram.types import Message, InputMediaPhoto, InputMediaVideo, InputMediaDocument
from adult_content_rewriter import AdultContentProcessor
from log_config import get_logger

logger = get_logger(__name__)

class AntiDetectionIntegration:
    """åæŸ¥é‡é›†æˆç±»"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–åæŸ¥é‡é›†æˆ"""
        self.config = config or {}
        self.processor = AdultContentProcessor()
        self.enabled = self.config.get('anti_detection_enabled', True)
        self.processing_stats = {
            "total_processed": 0,
            "successful_processed": 0,
            "failed_processed": 0,
            "similarity_reduced": 0
        }
        
        logger.info(f"ğŸ”§ åæŸ¥é‡ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ - å¯ç”¨çŠ¶æ€: {self.enabled}")
    
    async def process_message_for_cloning(self, message: Message, target_chat_id: str) -> Tuple[bool, Optional[Message], Optional[str]]:
        """ä¸ºæ¬è¿å¤„ç†æ¶ˆæ¯"""
        if not self.enabled:
            return True, message, None
        
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯åª’ä½“ç»„
            if message.media_group_id:
                return await self._process_media_group(message, target_chat_id)
            else:
                return await self._process_single_message(message, target_chat_id)
                
        except Exception as e:
            logger.error(f"âŒ åæŸ¥é‡å¤„ç†å¤±è´¥: {e}")
            self.processing_stats["failed_processed"] += 1
            return False, message, str(e)
    
    async def _process_media_group(self, message: Message, target_chat_id: str) -> Tuple[bool, Optional[Message], Optional[str]]:
        """å¤„ç†åª’ä½“ç»„"""
        try:
            # è·å–åª’ä½“ç»„çš„æ‰€æœ‰æ¶ˆæ¯
            media_group_messages = await self._get_media_group_messages(message)
            
            if not media_group_messages:
                return True, message, None
            
            # å¤„ç†æ–‡æœ¬å†…å®¹
            original_caption = message.caption or ""
            text_result = self.processor.content_rewriter.rewrite_content(original_caption)
            
            # å¤„ç†åª’ä½“æ–‡ä»¶
            processed_media = []
            for msg in media_group_messages:
                if msg.media:
                    processed_media.append(await self._process_media_file(msg))
            
            # åˆ›å»ºæ–°çš„åª’ä½“ç»„
            new_media_group = await self._create_new_media_group(processed_media, text_result)
            
            self.processing_stats["successful_processed"] += 1
            if text_result["similarity"] < 0.3:
                self.processing_stats["similarity_reduced"] += 1
            
            logger.info(f"âœ… åª’ä½“ç»„åæŸ¥é‡å¤„ç†å®Œæˆ - ç›¸ä¼¼åº¦: {text_result['similarity']:.2f}")
            
            return True, new_media_group, text_result["rewritten_content"]
            
        except Exception as e:
            logger.error(f"âŒ åª’ä½“ç»„å¤„ç†å¤±è´¥: {e}")
            return False, message, str(e)
    
    async def _process_single_message(self, message: Message, target_chat_id: str) -> Tuple[bool, Optional[Message], Optional[str]]:
        """å¤„ç†å•æ¡æ¶ˆæ¯"""
        try:
            if not message.text and not message.caption:
                return True, message, None
            
            # å¤„ç†æ–‡æœ¬å†…å®¹
            original_text = message.text or message.caption or ""
            text_result = self.processor.content_rewriter.rewrite_content(original_text)
            
            # åˆ›å»ºæ–°æ¶ˆæ¯
            new_message = await self._create_new_message(message, text_result)
            
            self.processing_stats["successful_processed"] += 1
            if text_result["similarity"] < 0.3:
                self.processing_stats["similarity_reduced"] += 1
            
            logger.info(f"âœ… å•æ¶ˆæ¯åæŸ¥é‡å¤„ç†å®Œæˆ - ç›¸ä¼¼åº¦: {text_result['similarity']:.2f}")
            
            return True, new_message, text_result["rewritten_content"]
            
        except Exception as e:
            logger.error(f"âŒ å•æ¶ˆæ¯å¤„ç†å¤±è´¥: {e}")
            return False, message, str(e)
    
    async def _get_media_group_messages(self, message: Message) -> List[Message]:
        """è·å–åª’ä½“ç»„çš„æ‰€æœ‰æ¶ˆæ¯"""
        # è¿™é‡Œéœ€è¦æ ¹æ®æ‚¨çš„å®é™…å®ç°æ¥è·å–åª’ä½“ç»„æ¶ˆæ¯
        # æš‚æ—¶è¿”å›å•ä¸ªæ¶ˆæ¯ï¼Œå®é™…å®ç°æ—¶éœ€è¦è·å–å®Œæ•´çš„åª’ä½“ç»„
        return [message]
    
    async def _process_media_file(self, message: Message) -> Dict[str, Any]:
        """å¤„ç†åª’ä½“æ–‡ä»¶"""
        return {
            "message": message,
            "file_id": message.file_id,
            "file_type": message.media.__class__.__name__,
            "processed": True,
            "new_identifier": self.processor.media_processor.generate_file_identifier(
                message.file_id,
                message.file_size or 0,
                int(time.time())
            )
        }
    
    async def _create_new_media_group(self, processed_media: List[Dict], text_result: Dict) -> Message:
        """åˆ›å»ºæ–°çš„åª’ä½“ç»„"""
        # è¿™é‡Œéœ€è¦æ ¹æ®æ‚¨çš„å®é™…å®ç°æ¥åˆ›å»ºæ–°çš„åª’ä½“ç»„
        # æš‚æ—¶è¿”å›åŸå§‹æ¶ˆæ¯ï¼Œå®é™…å®ç°æ—¶éœ€è¦åˆ›å»ºæ–°çš„åª’ä½“ç»„
        return processed_media[0]["message"] if processed_media else None
    
    async def _create_new_message(self, original_message: Message, text_result: Dict) -> Message:
        """åˆ›å»ºæ–°æ¶ˆæ¯"""
        # è¿™é‡Œéœ€è¦æ ¹æ®æ‚¨çš„å®é™…å®ç°æ¥åˆ›å»ºæ–°æ¶ˆæ¯
        # æš‚æ—¶è¿”å›åŸå§‹æ¶ˆæ¯ï¼Œå®é™…å®ç°æ—¶éœ€è¦åˆ›å»ºæ–°æ¶ˆæ¯
        return original_message
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.processing_stats.copy()
        stats.update(self.processor.get_processing_stats())
        
        # è®¡ç®—æˆåŠŸç‡
        if stats["total_processed"] > 0:
            stats["success_rate"] = stats["successful_processed"] / stats["total_processed"]
        else:
            stats["success_rate"] = 0.0
        
        # è®¡ç®—ç›¸ä¼¼åº¦é™ä½ç‡
        if stats["successful_processed"] > 0:
            stats["similarity_reduction_rate"] = stats["similarity_reduced"] / stats["successful_processed"]
        else:
            stats["similarity_reduction_rate"] = 0.0
        
        return stats
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.processing_stats = {
            "total_processed": 0,
            "successful_processed": 0,
            "failed_processed": 0,
            "similarity_reduced": 0
        }
        self.processor.reset_stats()

# é›†æˆåˆ°æ¬è¿å¼•æ“çš„è£…é¥°å™¨
def with_anti_detection(original_method):
    """åæŸ¥é‡è£…é¥°å™¨"""
    async def wrapper(self, *args, **kwargs):
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨åæŸ¥é‡
        if hasattr(self, 'anti_detection') and self.anti_detection.enabled:
            # åœ¨æ¬è¿å‰è¿›è¡ŒåæŸ¥é‡å¤„ç†
            result = await self.anti_detection.process_message_for_cloning(*args, **kwargs)
            if result[0]:  # å¤„ç†æˆåŠŸ
                return await original_method(self, *args, **kwargs)
            else:  # å¤„ç†å¤±è´¥
                logger.warning(f"âš ï¸ åæŸ¥é‡å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹: {result[2]}")
        
        return await original_method(self, *args, **kwargs)
    
    return wrapper

# é…ç½®ç¤ºä¾‹
ANTI_DETECTION_CONFIG = {
    "anti_detection_enabled": True,
    "similarity_threshold": 0.3,
    "auto_retry": True,
    "max_retry_attempts": 3,
    "retry_delay": 1.0,
    "logging_enabled": True,
    "stats_collection": True
}

