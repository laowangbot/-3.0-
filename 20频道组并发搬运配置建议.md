# 20个频道组并发搬运配置建议

## 🎯 需求分析

您希望一次性选择20个频道组进行同时搬运，这需要对当前系统的并发限制进行调整。

## 📊 当前限制分析

### 现有配置
- **系统总并发限制**: 20个任务
- **用户并发限制**: 3个任务
- **配置位置**: 
  - `config.py`: `max_concurrent_tasks = 10` (默认用户配置)
  - `cloning_engine.py`: `max_concurrent_tasks = 20` (引擎配置)
  - `cloning_engine.py`: 用户限制硬编码为3个

### 限制原因
1. **资源保护**: 防止单个用户占用过多系统资源
2. **API限制**: Telegram API有频率限制
3. **稳定性考虑**: 避免过多并发导致系统不稳定

## 🔧 修改建议

### 方案一：提升用户并发限制（推荐）

#### 1. 修改用户并发限制

**文件**: `cloning_engine.py` (第404行)

```python
# 原代码
if len(user_active_tasks) >= 3:
    logger.warning(f"用户 {user_id} 已达到最大并发任务数限制: 3")
    return False

# 修改为
max_user_concurrent = 20  # 或者从配置文件读取
if len(user_active_tasks) >= max_user_concurrent:
    logger.warning(f"用户 {user_id} 已达到最大并发任务数限制: {max_user_concurrent}")
    return False
```

#### 2. 添加配置选项

**文件**: `config.py` (在DEFAULT_USER_CONFIG中添加)

```python
# 任务设置
"max_concurrent_tasks": 10,  # 支持最多10个并发任务
"max_user_concurrent_tasks": 20,  # 用户最大并发任务数
"task_timeout": 3600,  # 1小时
```

#### 3. 动态读取配置

**文件**: `cloning_engine.py` (修改start_cloning方法)

```python
# 检查用户并发任务数限制
user_id = task.config.get('user_id') if task.config else None
if user_id:
    # 从用户配置读取限制
    user_config = await get_user_config(user_id)
    max_user_concurrent = user_config.get('max_user_concurrent_tasks', 20)
    
    user_active_tasks = [t for t in self.active_tasks.values() if t.config.get('user_id') == user_id]
    if len(user_active_tasks) >= max_user_concurrent:
        logger.warning(f"用户 {user_id} 已达到最大并发任务数限制: {max_user_concurrent}")
        return False
```

### 方案二：分批执行（保守方案）

如果不想修改并发限制，可以实现智能分批：

#### 1. 修改多任务执行逻辑

**文件**: `main.py` (修改_execute_multi_cloning方法)

```python
async def _execute_multi_cloning_batched(self, callback_query, user_id: str, task_configs: List[Dict]):
    """分批执行多任务搬运"""
    batch_size = 3  # 每批3个任务
    total_batches = (len(task_configs) + batch_size - 1) // batch_size
    
    for batch_num in range(total_batches):
        start_idx = batch_num * batch_size
        end_idx = min(start_idx + batch_size, len(task_configs))
        batch_configs = task_configs[start_idx:end_idx]
        
        await callback_query.message.reply_text(
            f"🚀 开始执行第 {batch_num + 1}/{total_batches} 批任务 ({len(batch_configs)} 个频道组)"
        )
        
        # 执行当前批次
        await self._execute_multi_cloning(callback_query, user_id, batch_configs)
        
        # 等待当前批次完成
        if batch_num < total_batches - 1:
            await asyncio.sleep(5)  # 批次间延迟
```

## ⚡ 性能优化建议

### 1. 调整消息处理参数

```python
# config.py 中的性能设置
"message_delay": 0.5,  # 减少消息间隔（从1.0秒降到0.5秒）
"batch_size": 20,      # 增加批量处理大小（从10增到20）
"retry_attempts": 2,   # 减少重试次数（从3降到2）
```

### 2. 添加资源监控

```python
import psutil

def check_system_resources():
    """检查系统资源使用情况"""
    cpu_percent = psutil.cpu_percent()
    memory_percent = psutil.virtual_memory().percent
    
    if cpu_percent > 80 or memory_percent > 80:
        logger.warning(f"系统资源使用率过高: CPU {cpu_percent}%, 内存 {memory_percent}%")
        return False
    return True
```

### 3. 智能延迟调整

```python
def calculate_dynamic_delay(active_tasks_count):
    """根据活跃任务数动态调整延迟"""
    base_delay = 0.5
    if active_tasks_count > 10:
        return base_delay * 1.5
    elif active_tasks_count > 5:
        return base_delay * 1.2
    return base_delay
```

## 🛡️ 风险评估与预防

### 潜在风险
1. **API频率限制**: Telegram可能限制过于频繁的请求
2. **内存消耗**: 20个并发任务会增加内存使用
3. **网络负载**: 大量并发可能导致网络拥塞
4. **错误处理**: 更多任务意味着更多潜在错误点

### 预防措施
1. **渐进式增加**: 先测试5个，再10个，再15个，最后20个
2. **监控告警**: 添加资源使用监控
3. **自动降级**: 检测到问题时自动减少并发数
4. **错误隔离**: 确保单个任务失败不影响其他任务

## 📝 实施步骤

### 立即可行的修改（推荐）

1. **修改用户并发限制**
   ```bash
   # 编辑 cloning_engine.py 第404行
   if len(user_active_tasks) >= 20:  # 改为20
   ```

2. **测试验证**
   - 先测试5个频道组
   - 再测试10个频道组
   - 最后测试20个频道组

3. **监控观察**
   - 观察系统资源使用
   - 检查任务完成率
   - 监控错误日志

### 完整优化方案

1. **添加配置选项** (config.py)
2. **实现动态配置读取** (cloning_engine.py)
3. **添加资源监控** (新增monitor模块)
4. **实现智能分批** (main.py)
5. **添加性能调优** (全局优化)

## 🎯 推荐配置

对于20个频道组的需求，推荐以下配置：

```python
# config.py
DEFAULT_USER_CONFIG = {
    # ... 其他配置 ...
    "max_concurrent_tasks": 20,        # 系统总限制
    "max_user_concurrent_tasks": 20,   # 用户限制
    "message_delay": 0.5,              # 消息间隔
    "batch_size": 20,                  # 批量大小
    "task_timeout": 7200,              # 2小时超时
}
```

这个配置在保证稳定性的同时，能够满足您20个频道组同时搬运的需求。

---

**注意**: 建议先进行小规模测试，确认系统稳定后再进行大规模部署。